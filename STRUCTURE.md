# Jarvis Mark III - Project Structure

```
jarvis/
│
├── main.py                     # Entry point
├── quickstart.py               # Quick start with checks
├── build.py                    # PyInstaller build script
├── config.yaml                 # Configuration file
├── requirements.txt            # Python dependencies
│
├── README.md                   # Overview and quick start
├── SETUP.md                    # Detailed setup guide
├── DEVELOPMENT.md              # Development guide
│
├── core/                       # Core subsystems
│   ├── __init__.py
│   ├── jarvis.py              # Main orchestrator
│   ├── logger.py              # Logging configuration
│   ├── stt.py                 # Speech-to-Text (Whisper)
│   ├── llm.py                 # AI Brain (Ollama)
│   ├── tts.py                 # Text-to-Speech (pyttsx3)
│   └── memory.py              # Memory system (SQLite)
│
├── skills/                     # Modular command skills
│   ├── __init__.py            # Skills engine
│   ├── system_skills.py       # System operations
│   ├── web_skills.py          # Web operations
│   ├── file_skills.py         # File operations
│   └── python_skills.py       # Python execution
│
├── ui/                         # User interface
│   ├── __init__.py
│   └── dashboard.py           # Tkinter GUI
│
├── tests/                      # Test scripts
│   ├── test_tts.py
│   ├── test_stt.py
│   └── test_llm.py
│
├── data/                       # Generated at runtime
│   └── jarvis_memory.db       # SQLite database
│
├── logs/                       # Generated at runtime
│   └── jarvis.log             # Application logs
│
└── dist/                       # Generated by build.py
    └── Jarvis.exe             # Standalone executable

```

## Module Descriptions

### Core Modules

**main.py**
- Entry point for the application
- Loads configuration
- Initializes Jarvis orchestrator
- Handles GUI/console mode selection

**core/jarvis.py**
- Main orchestrator that coordinates all subsystems
- Implements Listen → Think → Act → Speak pipeline
- Manages interaction loop

**core/stt.py** (Speech-to-Text)
- Handles voice input
- Supports local (faster-whisper) and API (OpenAI) modes
- Push-to-talk and wake word activation
- Audio recording and transcription

**core/llm.py** (AI Brain)
- LLM integration via Ollama
- Intent classification (command vs conversation)
- Entity extraction from commands
- Natural language response generation
- Context management

**core/tts.py** (Text-to-Speech)
- Voice output using pyttsx3
- SAPI5 integration (Windows native voices)
- Configurable voice characteristics
- Async and sync speech modes

**core/memory.py** (Memory System)
- SQLite-based persistent storage
- Conversation history
- User preferences
- Usage statistics
- Context retrieval for LLM

### Skills Modules

**skills/__init__.py**
- Skills engine that routes commands to appropriate skills
- Skill registration and discovery
- Safety controls (confirmation for dangerous operations)
- Base skill class definition

**skills/system_skills.py**
- Application launching
- Volume control (using pycaw)
- Screenshots (using pyautogui)
- System power operations (shutdown/restart)

**skills/web_skills.py**
- Web searches (Google)
- URL opening in default browser
- Browser control

**skills/file_skills.py**
- File creation, deletion
- Directory listing
- File operations

**skills/python_skills.py**
- Python script execution
- Code execution (sandboxed)
- Package management

### UI Module

**ui/dashboard.py**
- Minimal Tkinter-based GUI
- State indicators (idle/listening/thinking/speaking)
- Conversation history display
- Push-to-talk button
- Settings panel (future)
- Dark/light theme support

### Configuration

**config.yaml**
- Central configuration file
- STT settings (mode, model, activation)
- LLM settings (model, prompts, generation params)
- TTS settings (voice, rate, volume)
- Skills settings (enabled skills, permissions)
- Memory settings (database path, retention)
- UI settings (theme, window size)

### Build & Test

**build.py**
- PyInstaller configuration
- Builds standalone executable
- Includes dependencies and data files

**test_*.py**
- Component testing scripts
- TTS verification
- STT verification
- LLM connection testing

**quickstart.py**
- Pre-flight checks
- Dependency verification
- Ollama status check
- Configuration validation

## Data Flow

```
┌─────────────────────────────────────────────────────────────┐
│                        USER INPUT                            │
└──────────────────────┬──────────────────────────────────────┘
                       │
                       ▼
            ┌──────────────────────┐
            │   STT (core/stt.py)  │
            │   • Record audio     │
            │   • Transcribe       │
            └──────────┬───────────┘
                       │
                       ▼
            ┌──────────────────────┐
            │   LLM (core/llm.py)  │
            │   • Classify intent  │
            │   • Extract entities │
            │   • Generate response│
            └──────────┬───────────┘
                       │
                ┌──────┴──────┐
                │             │
        ┌───────▼─────┐  ┌────▼──────────┐
        │  COMMAND    │  │ CONVERSATION  │
        └───────┬─────┘  └────┬──────────┘
                │             │
                ▼             │
    ┌──────────────────────┐ │
    │ Skills Engine        │ │
    │ (skills/__init__.py) │ │
    └──────────┬───────────┘ │
               │             │
               ▼             │
    ┌──────────────────────┐ │
    │  Execute Skill       │ │
    │  • SystemSkills      │ │
    │  • WebSkills         │ │
    │  • FileSkills        │ │
    │  • PythonSkills      │ │
    └──────────┬───────────┘ │
               │             │
               └──────┬──────┘
                      │
                      ▼
           ┌──────────────────────┐
           │  TTS (core/tts.py)   │
           │  • Speak response    │
           └──────────┬───────────┘
                      │
                      ▼
           ┌──────────────────────┐
           │ Memory (core/memory) │
           │ • Store interaction  │
           │ • Update context     │
           └──────────────────────┘
```

## Extension Points

### Adding New Skills

1. Create new file in `skills/` directory
2. Inherit from `BaseSkill` class
3. Implement `can_handle()` and `execute()` methods
4. Register in `skills/__init__.py`
5. Enable in `config.yaml`

### Adding New LLM Providers

1. Create new provider class in `core/llm.py`
2. Implement same interface as `AIBrain`
3. Add configuration options
4. Update config.yaml with provider selection

### Adding New UI Components

1. Create new module in `ui/` directory
2. Import in `ui/__init__.py`
3. Integrate with `core/jarvis.py` orchestrator

## Dependencies Graph

```
main.py
  └─ core/jarvis.py
       ├─ core/stt.py
       │    ├─ faster-whisper (local mode)
       │    ├─ sounddevice (audio recording)
       │    └─ keyboard (activation)
       │
       ├─ core/llm.py
       │    └─ ollama (LLM communication)
       │
       ├─ core/tts.py
       │    └─ pyttsx3 (text-to-speech)
       │
       ├─ core/memory.py
       │    └─ sqlite3 (built-in)
       │
       ├─ skills/
       │    ├─ pyautogui (screenshots)
       │    ├─ pycaw (volume control)
       │    └─ webbrowser (built-in)
       │
       └─ ui/dashboard.py
            └─ tkinter (built-in)
```

## File Sizes (Approximate)

```
Source Code:        ~50 KB
Configuration:      ~5 KB
Dependencies:       ~500 MB (pip install)
Whisper Model:      140 MB - 1.5 GB (depending on model)
Ollama Model:       2 GB - 70 GB (depending on model)
Executable:         ~100 MB (with PyInstaller)
Runtime Data:       < 10 MB (logs + database)
```

## Performance Characteristics

**Startup Time**: 5-10 seconds
- Loading Whisper model: 2-5s
- Connecting to Ollama: 1-2s
- Initializing TTS: <1s

**Response Time** (per interaction):
- STT (local, base model): 1-3s
- STT (API): <0.5s
- LLM (3B model): 1-2s
- LLM (8B model): 3-5s
- TTS: 0.5-2s (depending on text length)
- Total latency: 3-10s

**Memory Usage**:
- Base application: 200-300 MB
- Whisper (base): +500 MB
- Ollama (3B model): +2 GB
- Total: ~3 GB RAM minimum

---

**This structure provides**:
- Clear separation of concerns
- Modularity and extensibility
- Easy testing and debugging
- Production-ready architecture
